# Knowledge Base Agent

A sophisticated personal knowledge management system that intelligently scrapes, processes, and synthesizes information from web sources. The system provides a powerful chat-based interface with chat history management, querying a curated personal knowledge base using locally-run AI models.

## ğŸ—ï¸ Architecture

**Two-Part Solution:**
1. **Backend (Python/FastAPI)**: Web scraping, vector database, RAG implementation, and SQLite for chat history
2. **Frontend (Next.js 15)**: Modern chat interface with sidebar for previous conversations and real-time communication

## ğŸš€ Features

- âœ… **Modern UI**: Clean chat interface with sidebar for conversation history
- âœ… **SQLite Integration**: Chat history stored in local database
- âœ… **Real-time Chat**: Instant messaging with AI responses
- âœ… **Source Attribution**: AI responses include relevant source citations
- âœ… **Mobile Responsive**: Works on desktop and mobile devices
- âœ… **Local AI**: Complete privacy with local LLM processing (Ollama)
- âœ… **Vector Search**: Semantic search across knowledge base
- âœ… **Chat Management**: Create, view, and delete chat sessions
- âœ… **Web Scraping**: Intelligent content extraction from web sources
- âœ… **Document Upload**: Upload and process PDF, TXT, and EPUB files with improved handling

## âš¡ Quick Start

**Run everything with one command:**

```bash
# Start all services (SQLite, Ollama, Backend, Frontend)
make dev
```

**Or use the startup script directly:**

```bash
./start-dev.sh
```

**Available commands:**
- `make dev` - Start all services
- `make stop` - Stop all services  
- `make setup` - Initial setup and installation
- `make clean` - Clean up generated files

The script automatically:
- âœ… Checks system requirements
- âœ… Creates SQLite database if needed
- âœ… Starts Ollama and downloads AI models
- âœ… Installs dependencies if needed
- âœ… Starts backend and frontend servers
- âœ… Provides helpful status messages

**Access points:**
- ğŸŒ **Frontend**: http://localhost:3000
- ğŸ”§ **Backend API**: http://localhost:8000
- ğŸ“š **API Docs**: http://localhost:8000/docs

Press `Ctrl+C` to stop all services.

## ğŸ“‹ Prerequisites

- **macOS** (optimized for M4 Pro)
- **Python 3.11**
- **Node.js 18+**
- **Ollama** (for local AI models)

## ğŸ› ï¸ Installation

### Option 1: Automated Installation (Recommended)

```bash
# Clone or navigate to the project directory
cd /Users/ekip.kalir/Projects/Personal/knowledge-base-agent

# Run the automated installation script
./install.sh
```

### Option 2: Manual Installation

#### 1. Install System Dependencies

```bash
# Install essential development tools
brew install curl wget tree htop git

# Install Python 3.11
brew install python@3.11

# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh
```

#### 2. Backend Setup

```bash
cd knowledge-base-agent-backend

# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
playwright install

# Initialize database
python init_db.py
```

#### 3. Frontend Setup

```bash
cd ../knowledge-base-agent-frontend

# Install dependencies
npm install
```

#### 4. Install AI Models

```bash
# Pull required Ollama models
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

## ğŸš€ Running the Application

### Option 1: Automated Startup (Recommended)

```bash
# Start all services with one command
./start-dev.sh
```

This will start:
- Ollama service
- Backend API server (port 8000)
- Frontend development server (port 3000)

### Option 2: Manual Startup

#### Terminal 1: Start Backend (Required)
```bash
# Quick start backend
./start-backend.sh

# OR manually:
cd knowledge-base-agent-backend
source venv/bin/activate
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Terminal 2: Start Frontend
```bash
cd knowledge-base-agent-frontend
npm run dev
```

#### Optional: Start Ollama (for AI features)
```bash
ollama serve
```

## ğŸŒ Access Points

- **Frontend Application**: http://localhost:3000
- **Backend API**: http://localhost:8000
- **API Documentation**: http://localhost:8000/docs
- **Database**: SQLite file at `./data/knowledge_base.db`

## ğŸ“š API Endpoints

### Chat Endpoints
- `POST /api/v1/chat/sessions` - Create new chat session
- `GET /api/v1/chat/sessions` - Get recent chat sessions (last 15)
- `GET /api/v1/chat/sessions/{id}/messages` - Get messages for a session
- `POST /api/v1/chat/sessions/{id}/messages` - Send message and get AI response
- `DELETE /api/v1/chat/sessions/{id}` - Delete chat session

### Knowledge Base Endpoints
- `POST /api/v1/scrape` - Scrape web content and add to knowledge base
- `POST /api/v1/upload` - Upload documents (PDF, TXT, EPUB) to knowledge base
- `GET /api/v1/sources` - Get knowledge sources
- `POST /api/v1/query` - Query knowledge base directly

## ğŸ”§ Configuration

### Backend Configuration (.env)
```env
# Application Settings
APP_NAME="Knowledge Base Agent Backend"
APP_VERSION="0.1.0"
DEBUG=true

# Database Settings
DATABASE_URL="sqlite+aiosqlite:///./data/knowledge_base.db"

# Vector Database
VECTOR_DB_TYPE="chromadb"
CHROMA_DB_PATH="./data/chroma_db"

# Ollama Settings
OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_CHAT_MODEL="llama3.1:8b"
OLLAMA_EMBED_MODEL="nomic-embed-text"

# API Settings
API_V1_STR="/api/v1"
CORS_ORIGINS=["http://localhost:3000"]

# File Upload
MAX_UPLOAD_SIZE_MB=100
```

### Frontend Configuration (.env.local)
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_APP_NAME="Knowledge Base Agent"
NEXT_PUBLIC_WS_URL=ws://localhost:8000/ws
```

## ğŸ“– Usage Guide

### 1. First Time Setup
1. Start the application using `./start-dev.sh`
2. Navigate to http://localhost:3000
3. Click "New Chat" to start your first conversation

### 2. Adding Knowledge Sources

#### Web Scraping
```bash
# Using curl to add a web source
curl -X POST "http://localhost:8000/api/v1/scrape" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com/article"}'
```

#### Document Upload
```bash
# Upload a document via curl
curl -X POST "http://localhost:8000/api/v1/upload" \
  -F "file=@/path/to/your/document.txt"

# Supported formats: PDF, TXT, EPUB
# Maximum file size: 100MB
```

#### Using the Web Interface
1. Navigate to http://localhost:3000
2. Use the "Upload Documents" section to select and upload files
3. Drag and drop files or click "Choose File" to browse
4. Supported formats: PDF, TXT, EPUB files

### 3. Chatting with Your Knowledge Base
1. Type your question in the chat interface
2. The AI will search your knowledge base for relevant information
3. Responses include source citations when relevant content is found
4. Chat history is automatically saved and accessible from the sidebar

### 4. Managing Chat Sessions
- **Create**: Click "New Chat" in the sidebar
- **View**: Click on any previous chat in the sidebar
- **Delete**: Hover over a chat and click the trash icon

## ğŸ› ï¸ Development

### Project Structure
```
knowledge-base-agent/
â”œâ”€â”€ knowledge-base-agent-backend/     # Python FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/endpoints/           # API route handlers
â”‚   â”‚   â”œâ”€â”€ core/                    # Configuration and database
â”‚   â”‚   â”œâ”€â”€ models/                  # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas/                 # Pydantic schemas
â”‚   â”‚   â””â”€â”€ services/                # Business logic services
â”‚   â”œâ”€â”€ data/                        # SQLite database and vector store
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ knowledge-base-agent-frontend/    # Next.js 15 frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/                     # Next.js app router
â”‚   â”‚   â”œâ”€â”€ components/              # React components
â”‚   â”‚   â”œâ”€â”€ lib/                     # Utilities and API client
â”‚   â”‚   â”œâ”€â”€ stores/                  # Zustand state management
â”‚   â”‚   â””â”€â”€ types/                   # TypeScript definitions
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ install.sh                       # Automated installation
â”œâ”€â”€ start-dev.sh                     # Development startup script
â””â”€â”€ README.md
```

### Key Technologies
- **Backend**: FastAPI, SQLAlchemy, SQLite, ChromaDB, Playwright, BeautifulSoup
- **Frontend**: Next.js 15, TypeScript, Tailwind CSS, Zustand, Radix UI
- **AI/ML**: Ollama (llama3.1:8b), Sentence Transformers, ChromaDB
- **Database**: SQLite with JSON support

## ğŸ” Troubleshooting

### Common Issues

1. **Database Initialization Error**
   ```bash
   cd knowledge-base-agent-backend
   python init_db.py
   ```

2. **Ollama Models Not Found**
   ```bash
   ollama pull llama3.1:8b
   ollama pull nomic-embed-text
   ```

3. **Frontend Build Issues**
   ```bash
   cd knowledge-base-agent-frontend
   rm -rf node_modules package-lock.json
   npm install
   ```

4. **Backend Import Errors**
   ```bash
   cd knowledge-base-agent-backend
   source venv/bin/activate
   export PYTHONPATH="${PYTHONPATH}:$(pwd)"
   ```

### Document Processing
For better document processing capabilities, install these optional dependencies:
```bash
pip install PyPDF2 ebooklib beautifulsoup4
```

### Logs and Debugging
- Backend logs: Check terminal running uvicorn
- Frontend logs: Check browser console and terminal running npm
- Database: Examine SQLite file with `sqlite3 ./data/knowledge_base.db`

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License.

## ğŸ™ Acknowledgments

- Built with FastAPI, Next.js, and Ollama
- Uses ChromaDB for vector storage
- Powered by local AI models for privacy
